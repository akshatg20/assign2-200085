Q1: Basic implementation of how neural networks can learn any boolean function. 

Q2: Q-learning Agent based on Reinforcement Learning
1. Generated a random instance of the frozen lake scenario given two inputs - the size of the lake (N) assuming its square, and the number of holes (M).
2. Implemented a Q-learning agent to find a path through the lake to the goal. Reported the results of the learning algorithm by plotting episode count on the x-axis and total reward received by the agent within an episode on the y-axis
3. Identified how learning performance changes when you change the parameters α and λ in your algorithm
4. Identified how learning performance changes with respect to changes in N and M.

Q3: Analysis of Neuron-Spiking behaviour using a Rukolv Map

The Rulkov map is a simple dynamical systems model of neuronal action potentials. For some specific parameter choices, this system can reproduce the broad outlines of neuronal action potentials, viz. bursts of spikes, tonic spiking and periods of silence. I have reproduced all three modes of behavior using this model. Hints for the appropiate parameter values were taken from the following [paper](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.65.041922) 
